{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "matplotlib.style.use('seaborn-notebook')\n",
    "matplotlib.pyplot.rcParams['figure.figsize'] = (16, 10)\n",
    "matplotlib.pyplot.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.1 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4365"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "exp_dir = \"../exps/task1/two_headed_best/\"\n",
    "dev_outputs = defaultdict(list)\n",
    "\n",
    "def load_exps(exp_dir):\n",
    "    experiments = []\n",
    "    for subdir in os.scandir(exp_dir):\n",
    "        dev_fn = os.path.join(subdir.path, \"dev.out\")\n",
    "        if not os.path.exists(dev_fn):\n",
    "            print(\"No dev.out: {}\".format(subdir.path))\n",
    "            continue\n",
    "        config_fn = os.path.join(subdir.path, \"config.yaml\")\n",
    "        with open(config_fn) as f:\n",
    "            config = yaml.load(f)\n",
    "        config['config_language'] = config['language']\n",
    "        config['language'] = '-'.join(config['dev_file'].split('/')[-1].split('-')[:-1])\n",
    "        config['train_size'] = config['train_file'].split('/')[-1].split('-')[-1]\n",
    "        exp_d = config\n",
    "        dev_output = pd.read_table(dev_fn, names=[\"lemma\", \"inflected\", \"tags\"])\n",
    "        if len(dev_output['inflected']) == 0:\n",
    "            print(subdir.path)\n",
    "        \n",
    "        dev_outputs[(config['language'], config['train_size'])].append(dev_output)\n",
    "        \n",
    "        dev_acc_fn = os.path.join(subdir.path, \"dev.word_accuracy\")\n",
    "        if not os.path.exists(dev_acc_fn):\n",
    "            print(\"Dev accuracy file does not exist in dir: {}\".format(subdir.path))\n",
    "        else:\n",
    "            with open(dev_acc_fn) as f:\n",
    "                exp_d['dev_acc'] = float(f.read())\n",
    "        experiments.append(exp_d)\n",
    "    experiments = pd.DataFrame(experiments)\n",
    "    return experiments\n",
    "        \n",
    "experiments = load_exps(exp_dir)\n",
    "sum(len(v) for v in dev_outputs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = {}\n",
    "\n",
    "for fn in os.scandir(\"../data/conll2018/task1/all\"):\n",
    "    if not fn.path.endswith('-dev'):\n",
    "        continue\n",
    "    language = '-'.join(fn.name.split('-')[:-1])\n",
    "    with open(fn.path) as f:\n",
    "        inflected = [l.strip().split('\\t')[1] for l in f]\n",
    "        gold[language] = pd.Series(inflected)\n",
    "\n",
    "for fn in os.scandir(\"../data/conll2018/task1/surprise\"):\n",
    "    if not fn.path.endswith('-dev'):\n",
    "        continue\n",
    "    language = '-'.join(fn.name.split('-')[:-1])\n",
    "    with open(fn.path) as f:\n",
    "        inflected = [l.strip().split('\\t')[1] for l in f]\n",
    "        gold[language] = pd.Series(inflected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>1290.0</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.102617</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>0.97200</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>1545.0</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.040310</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>1530.0</td>\n",
       "      <td>0.467520</td>\n",
       "      <td>0.305044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.4465</td>\n",
       "      <td>0.75175</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count      mean       std    min    25%     50%      75%   max\n",
       "train_size                                                                 \n",
       "high        1290.0  0.907692  0.102617  0.001  0.866  0.9380  0.97200  1.00\n",
       "low         1545.0  0.012261  0.040310  0.000  0.000  0.0000  0.00000  0.48\n",
       "medium      1530.0  0.467520  0.305044  0.000  0.196  0.4465  0.75175  1.00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments.groupby('train_size').dev_acc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "      <th>inflected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>obellī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "      <td>ovillī</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trȳgōnibus</td>\n",
       "      <td>trȳgōnibus</td>\n",
       "      <td>trygōnibus</td>\n",
       "      <td>trygōnibus</td>\n",
       "      <td>trȳgōnibus</td>\n",
       "      <td>trȳgōnibus</td>\n",
       "      <td>trȳgōnibus</td>\n",
       "      <td>trȳginibus</td>\n",
       "      <td>trȳgōnibus</td>\n",
       "      <td>torgīs</td>\n",
       "      <td>trȳgōnibus</td>\n",
       "      <td>trygonibus</td>\n",
       "      <td>trȳgīs</td>\n",
       "      <td>trȳgōnibus</td>\n",
       "      <td>trygōnibus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "      <td>largīvissētis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>compensāverit</td>\n",
       "      <td>compensāverit</td>\n",
       "      <td>compenserit</td>\n",
       "      <td>compensāverit</td>\n",
       "      <td>compensāverit</td>\n",
       "      <td>compenserit</td>\n",
       "      <td>compenserit</td>\n",
       "      <td>compensāverit</td>\n",
       "      <td>compensāverit</td>\n",
       "      <td>compensāverit</td>\n",
       "      <td>compensāverit</td>\n",
       "      <td>compensāverit</td>\n",
       "      <td>compensāverit</td>\n",
       "      <td>compensāverit</td>\n",
       "      <td>compenserit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comperīrer</td>\n",
       "      <td>comperiārer</td>\n",
       "      <td>comperīrer</td>\n",
       "      <td>comperiārer</td>\n",
       "      <td>comperīrer</td>\n",
       "      <td>comperīrer</td>\n",
       "      <td>comperierer</td>\n",
       "      <td>comperīrer</td>\n",
       "      <td>comperiēbar</td>\n",
       "      <td>comperīrer</td>\n",
       "      <td>comperīrer</td>\n",
       "      <td>comperiārer</td>\n",
       "      <td>comperīrer</td>\n",
       "      <td>comperīrer</td>\n",
       "      <td>comperīrer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       inflected      inflected      inflected      inflected      inflected  \\\n",
       "0         ovillī         ovillī         ovillī         ovillī         ovillī   \n",
       "1     trȳgōnibus     trȳgōnibus     trygōnibus     trygōnibus     trȳgōnibus   \n",
       "2  largīvissētis  largīvissētis  largīvissētis  largīvissētis  largīvissētis   \n",
       "3  compensāverit  compensāverit    compenserit  compensāverit  compensāverit   \n",
       "4     comperīrer    comperiārer     comperīrer    comperiārer     comperīrer   \n",
       "\n",
       "     inflected      inflected      inflected      inflected      inflected  \\\n",
       "0       ovillī         ovillī         ovillī         ovillī         obellī   \n",
       "1   trȳgōnibus     trȳgōnibus     trȳginibus     trȳgōnibus         torgīs   \n",
       "2  largissētis  largīvissētis  largīvissētis  largīvissētis  largīvissētis   \n",
       "3  compenserit    compenserit  compensāverit  compensāverit  compensāverit   \n",
       "4   comperīrer    comperierer     comperīrer    comperiēbar     comperīrer   \n",
       "\n",
       "       inflected      inflected      inflected      inflected      inflected  \n",
       "0         ovillī         ovillī         ovillī         ovillī         ovillī  \n",
       "1     trȳgōnibus     trygonibus         trȳgīs     trȳgōnibus     trygōnibus  \n",
       "2  largīvissētis  largīvissētis  largīvissētis  largīvissētis  largīvissētis  \n",
       "3  compensāverit  compensāverit  compensāverit  compensāverit    compenserit  \n",
       "4     comperīrer    comperiārer     comperīrer     comperīrer     comperīrer  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = {}\n",
    "for (lang, size), outputs in dev_outputs.items():\n",
    "    output = pd.concat(outputs, axis=1)\n",
    "    merged[(lang, size)] = pd.concat(outputs, axis=1)['inflected']\n",
    "    \n",
    "merged[('latin', 'high')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for (lang, size), outputs in merged.items():\n",
    "    d = {'language': lang, 'train_size': size}\n",
    "    for i in range(outputs.shape[1]):\n",
    "        acc = (outputs.iloc[:, i] == gold[lang]).mean()\n",
    "        d[i] = acc\n",
    "    d['majority'] = (outputs.mode(axis=1).iloc[:, 0] == gold[lang]).mean()\n",
    "    results.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_results['majority_wins'] = dev_results[dev_results.columns[2:-1]].max(axis=1) < dev_results.majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    227\n",
       "True      64\n",
       "Name: majority_wins, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_results[dev_results['train_size']=='low'].majority_wins.value_counts()\n",
    "dev_results.majority_wins.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../config/task1/highest_dev_acc\"\n",
    "keep = ['batch_size', 'commit_hash', 'dataset_class', 'dropout', 'early_stopping_window', 'epochs',\n",
    " 'inflected_embedding_size', 'inflected_hidden_size', 'inflected_num_layers', \n",
    " 'lemma_embedding_size', 'lemma_hidden_size', 'lemma_num_layers', 'model', \n",
    " 'numpy_random_seed', 'optimizer', 'share_vocab', \n",
    " 'tag_embedding_size', 'tag_hidden_size', 'tag_num_layers', 'train_file', 'dev_file',\n",
    " 'save_min_epoch', 'torch_random_seed']\n",
    "\n",
    "for (lang, train_size), idx in experiments.groupby(['language', 'train_size']).dev_acc.idxmax().iteritems():\n",
    "    out_fn = os.path.join(outdir, \"{}_{}.yaml\".format(lang, train_size))\n",
    "    in_config = experiments.loc[idx].experiment_dir + \"/config.yaml\"\n",
    "    with open(in_config) as f:\n",
    "        cfg = yaml.load(f)\n",
    "    cfg = {k: v for k, v in cfg.items() if k in keep}\n",
    "    cfg['train_file'] = 'data/conll2018' + cfg['train_file'].split('conll2018')[1]\n",
    "    cfg['dev_file'] = 'data/conll2018' + cfg['dev_file'].split('conll2018')[1]\n",
    "    with open(out_fn, 'w') as f:\n",
    "        yaml.dump(cfg, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 1\n",
    "\n",
    "Model with the highest dev acc, no majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../submissions/task1/01/task1\"\n",
    "for (lang, train_size), idx in experiments.groupby(['language', 'train_size']).dev_acc.idxmax().iteritems():\n",
    "    exp = experiments.loc[idx]\n",
    "    test_output = os.path.join(exp.experiment_dir, \"test.out\")\n",
    "    submission_path = os.path.join(output_dir, \"{}-{}-out\".format(lang, train_size))\n",
    "    shutil.copy2(test_output, submission_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 2\n",
    "\n",
    "Simple majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../submissions/task1/02/task1\"\n",
    "for (lang, train_size), group in experiments.groupby(['language', 'train_size']).groups.items():\n",
    "    all_outputs = None\n",
    "    for i, idx in enumerate(group):\n",
    "        exp = experiments.loc[idx]\n",
    "        test_fn = os.path.join(exp.experiment_dir, \"test.out\")\n",
    "        test_output = pd.read_table(test_fn, names=['lemma', i, 'tags'])\n",
    "        if all_outputs is None:\n",
    "            all_outputs = test_output[[i]]\n",
    "        else:\n",
    "            all_outputs = pd.concat((all_outputs, test_output[[i]]), axis=1)\n",
    "    majority = pd.concat((test_output[['lemma']], all_outputs.mode(axis=1)[0], test_output[['tags']]), axis=1)\n",
    "    output_fn = os.path.join(output_dir, \"{}-{}-out\".format(lang, train_size))\n",
    "    majority.to_csv(output_fn, index=False, header=False, sep=\"\\t\", na_rep='nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 3\n",
    "\n",
    "batch size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.34 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4365"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "exp_dir = \"../exps/task1/two_headed_best/\"\n",
    "\n",
    "def load_exps(exp_dir):\n",
    "    experiments = []\n",
    "    for subdir in os.scandir(exp_dir):\n",
    "        dev_fn = os.path.join(subdir.path, \"dev.batch16.out\")\n",
    "        if not os.path.exists(dev_fn):\n",
    "            print(\"No dev.out: {}\".format(subdir.path))\n",
    "            continue\n",
    "        config_fn = os.path.join(subdir.path, \"config.yaml\")\n",
    "        with open(config_fn) as f:\n",
    "            config = yaml.load(f)\n",
    "        config['config_language'] = config['language']\n",
    "        config['language'] = '-'.join(config['dev_file'].split('/')[-1].split('-')[:-1])\n",
    "        config['train_size'] = config['train_file'].split('/')[-1].split('-')[-1]\n",
    "        exp_d = config\n",
    "        dev_acc_fn = os.path.join(subdir.path, \"dev.batch16.word_accuracy\")\n",
    "        if not os.path.exists(dev_acc_fn):\n",
    "            print(\"Dev accuracy file does not exist in dir: {}\".format(subdir.path))\n",
    "        else:\n",
    "            with open(dev_acc_fn) as f:\n",
    "                exp_d['dev_acc'] = float(f.read())\n",
    "        experiments.append(exp_d)\n",
    "    experiments = pd.DataFrame(experiments)\n",
    "    return experiments\n",
    "        \n",
    "experiments = load_exps(exp_dir)\n",
    "sum(len(v) for v in dev_outputs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../submissions/task1/03/task1\"\n",
    "for (lang, train_size), idx in experiments.groupby(['language', 'train_size']).dev_acc.idxmax().iteritems():\n",
    "    exp = experiments.loc[idx]\n",
    "    test_output = os.path.join(exp.experiment_dir, \"test.out\")\n",
    "    submission_path = os.path.join(output_dir, \"{}-{}-out\".format(lang, train_size))\n",
    "    shutil.copy2(test_output, submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2 - Track 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test output file does not exist in ../exps/task2/track1/default/0162\n",
      "Test output file does not exist in ../exps/task2/track1/default/0163\n",
      "Test output file does not exist in ../exps/task2/track1/default/0164\n",
      "Test output file does not exist in ../exps/task2/track1/default/0165\n",
      "Test output file does not exist in ../exps/task2/track1/default/0166\n"
     ]
    }
   ],
   "source": [
    "exp_dirs = [\"../exps/task2/track1/final\", \"../exps/task2/track1/default\"]\n",
    "task2_track1 = []\n",
    "\n",
    "for exp_dir in exp_dirs:\n",
    "    for subdir in os.scandir(exp_dir):\n",
    "        config_fn = os.path.join(subdir.path, \"config.yaml\")\n",
    "        with open(config_fn) as f:\n",
    "            config = yaml.load(f)\n",
    "        exp_d = config\n",
    "        exp_d['language'] = config['train_file'].split('/')[-1].split('-')[0]\n",
    "        exp_d['train_size'] = config['train_file'].split('/')[-1].split('-')[2]\n",
    "        dev_acc_fn = os.path.join(subdir.path, \"dev.word_accuracy\")\n",
    "        if not os.path.exists(dev_acc_fn):\n",
    "            print(\"Dev accuracy file does not exist in {}\".format(subdir.path))\n",
    "        else:\n",
    "            with open(dev_acc_fn) as f:\n",
    "                exp_d['dev_acc'] = float(f.read())\n",
    "        test_out_fn = os.path.join(subdir.path, \"test.out\")\n",
    "        if not os.path.exists(test_out_fn):\n",
    "            print(\"Test output file does not exist in {}\".format(subdir.path))\n",
    "        else:\n",
    "            exp_d['test_output_path'] = test_out_fn\n",
    "            \n",
    "        task2_track1.append(exp_d)\n",
    "        \n",
    "task2_track1 = pd.DataFrame(task2_track1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">de</th>\n",
       "      <th>high</th>\n",
       "      <td>0.593093</td>\n",
       "      <td>0.741742</td>\n",
       "      <td>0.199972</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.136470</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.124969</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.420087</td>\n",
       "      <td>0.624625</td>\n",
       "      <td>0.240055</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">en</th>\n",
       "      <th>high</th>\n",
       "      <td>0.617794</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.190157</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.332353</td>\n",
       "      <td>0.545309</td>\n",
       "      <td>0.247739</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.478437</td>\n",
       "      <td>0.610666</td>\n",
       "      <td>0.172554</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">es</th>\n",
       "      <th>high</th>\n",
       "      <td>0.497256</td>\n",
       "      <td>0.551146</td>\n",
       "      <td>0.069132</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.152361</td>\n",
       "      <td>0.229718</td>\n",
       "      <td>0.078173</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.308299</td>\n",
       "      <td>0.394621</td>\n",
       "      <td>0.117447</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">fi</th>\n",
       "      <th>high</th>\n",
       "      <td>0.394072</td>\n",
       "      <td>0.462520</td>\n",
       "      <td>0.057271</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.044989</td>\n",
       "      <td>0.095162</td>\n",
       "      <td>0.036843</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.165670</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.038634</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">fr</th>\n",
       "      <th>high</th>\n",
       "      <td>0.595921</td>\n",
       "      <td>0.671299</td>\n",
       "      <td>0.080760</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.107035</td>\n",
       "      <td>0.244713</td>\n",
       "      <td>0.104946</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.376056</td>\n",
       "      <td>0.464653</td>\n",
       "      <td>0.083996</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ru</th>\n",
       "      <th>high</th>\n",
       "      <td>0.624612</td>\n",
       "      <td>0.692633</td>\n",
       "      <td>0.088557</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.127717</td>\n",
       "      <td>0.209145</td>\n",
       "      <td>0.094539</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.281118</td>\n",
       "      <td>0.403895</td>\n",
       "      <td>0.152874</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sv</th>\n",
       "      <th>high</th>\n",
       "      <td>0.594822</td>\n",
       "      <td>0.691099</td>\n",
       "      <td>0.113861</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.118674</td>\n",
       "      <td>0.280977</td>\n",
       "      <td>0.122318</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.327807</td>\n",
       "      <td>0.390925</td>\n",
       "      <td>0.068089</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean       max       std  size\n",
       "language train_size                                    \n",
       "de       high        0.593093  0.741742  0.199972     8\n",
       "         low         0.136470  0.270270  0.124969     9\n",
       "         medium      0.420087  0.624625  0.240055     9\n",
       "en       high        0.617794  0.732558  0.190157     9\n",
       "         low         0.332353  0.545309  0.247739     9\n",
       "         medium      0.478437  0.610666  0.172554     9\n",
       "es       high        0.497256  0.551146  0.069132     9\n",
       "         low         0.152361  0.229718  0.078173     9\n",
       "         medium      0.308299  0.394621  0.117447     9\n",
       "fi       high        0.394072  0.462520  0.057271     8\n",
       "         low         0.044989  0.095162  0.036843     8\n",
       "         medium      0.165670  0.210526  0.038634     8\n",
       "fr       high        0.595921  0.671299  0.080760     8\n",
       "         low         0.107035  0.244713  0.104946     8\n",
       "         medium      0.376056  0.464653  0.083996    44\n",
       "ru       high        0.624612  0.692633  0.088557     7\n",
       "         low         0.127717  0.209145  0.094539     7\n",
       "         medium      0.281118  0.403895  0.152874     7\n",
       "sv       high        0.594822  0.691099  0.113861     6\n",
       "         low         0.118674  0.280977  0.122318     6\n",
       "         medium      0.327807  0.390925  0.068089     6"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2_track1.groupby(['language', 'train_size']).dev_acc.agg(['mean', 'max', 'std', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>char_embedding_size</th>\n",
       "      <th>commit_hash</th>\n",
       "      <th>context_hidden_size</th>\n",
       "      <th>context_num_layers</th>\n",
       "      <th>dataset_class</th>\n",
       "      <th>decoder_hidden_size</th>\n",
       "      <th>decoder_num_layers</th>\n",
       "      <th>defaults</th>\n",
       "      <th>...</th>\n",
       "      <th>torch_random_seed</th>\n",
       "      <th>toy_eval</th>\n",
       "      <th>train_file</th>\n",
       "      <th>train_size</th>\n",
       "      <th>use_eos</th>\n",
       "      <th>use_step</th>\n",
       "      <th>vocab_path_src</th>\n",
       "      <th>vocab_path_tgt</th>\n",
       "      <th>word_hidden_size</th>\n",
       "      <th>word_num_layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>30</td>\n",
       "      <td>818c7f814ba005b6165d3cca297ee3e4f58bc354</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMORPOHTask2Track1Dataset</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>{'cell_type': 'LSTM', 'dataset_class': 'Labele...</td>\n",
       "      <td>...</td>\n",
       "      <td>788145932</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>16</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>40</td>\n",
       "      <td>c5c59d5ebef7b8d35aa5f146653c5d93ce8c8230</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMORPOHTask2Track1Dataset</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'cell_type': 'LSTM', 'dataset_class': 'Labele...</td>\n",
       "      <td>...</td>\n",
       "      <td>1839500317</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>16</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>40</td>\n",
       "      <td>2cccbc9dae4ab04eac491a3fe3fe02d7f1ed581b</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMORPOHTask2Track1Dataset</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'cell_type': 'LSTM', 'dataset_class': 'Labele...</td>\n",
       "      <td>...</td>\n",
       "      <td>1818896580</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>16</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>40</td>\n",
       "      <td>be844cc98b151054ad0ef5b1a2848d14f8d07c3b</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMORPOHTask2Track1Dataset</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>{'cell_type': 'LSTM', 'dataset_class': 'Labele...</td>\n",
       "      <td>...</td>\n",
       "      <td>604302163</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>32</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>40</td>\n",
       "      <td>2169238bc622c22c5162642080af87762526d894</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMORPOHTask2Track1Dataset</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>{'cell_type': 'LSTM', 'dataset_class': 'Labele...</td>\n",
       "      <td>...</td>\n",
       "      <td>747061712</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>32</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>40</td>\n",
       "      <td>a5c83b8eccd0becea5faab3e15ddd45accca7944</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMORPOHTask2Track1Dataset</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>{'cell_type': 'LSTM', 'dataset_class': 'Labele...</td>\n",
       "      <td>...</td>\n",
       "      <td>1962390220</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>/mnt/permanent/home/judit/projects/sigmorphon2...</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_size cell_type  char_embedding_size  \\\n",
       "18           32      LSTM                   30   \n",
       "52           16      LSTM                   40   \n",
       "74           16      LSTM                   40   \n",
       "94           16      LSTM                   40   \n",
       "118          32      LSTM                   40   \n",
       "138          32      LSTM                   40   \n",
       "\n",
       "                                  commit_hash  context_hidden_size  \\\n",
       "18   818c7f814ba005b6165d3cca297ee3e4f58bc354                  256   \n",
       "52   c5c59d5ebef7b8d35aa5f146653c5d93ce8c8230                  128   \n",
       "74   2cccbc9dae4ab04eac491a3fe3fe02d7f1ed581b                  128   \n",
       "94   be844cc98b151054ad0ef5b1a2848d14f8d07c3b                  256   \n",
       "118  2169238bc622c22c5162642080af87762526d894                  256   \n",
       "138  a5c83b8eccd0becea5faab3e15ddd45accca7944                  256   \n",
       "\n",
       "     context_num_layers                dataset_class  decoder_hidden_size  \\\n",
       "18                    1  SIGMORPOHTask2Track1Dataset                   64   \n",
       "52                    1  SIGMORPOHTask2Track1Dataset                  128   \n",
       "74                    1  SIGMORPOHTask2Track1Dataset                  128   \n",
       "94                    1  SIGMORPOHTask2Track1Dataset                  256   \n",
       "118                   1  SIGMORPOHTask2Track1Dataset                  256   \n",
       "138                   1  SIGMORPOHTask2Track1Dataset                  256   \n",
       "\n",
       "     decoder_num_layers                                           defaults  \\\n",
       "18                    1  {'cell_type': 'LSTM', 'dataset_class': 'Labele...   \n",
       "52                    1  {'cell_type': 'LSTM', 'dataset_class': 'Labele...   \n",
       "74                    1  {'cell_type': 'LSTM', 'dataset_class': 'Labele...   \n",
       "94                    1  {'cell_type': 'LSTM', 'dataset_class': 'Labele...   \n",
       "118                   1  {'cell_type': 'LSTM', 'dataset_class': 'Labele...   \n",
       "138                   1  {'cell_type': 'LSTM', 'dataset_class': 'Labele...   \n",
       "\n",
       "          ...         torch_random_seed toy_eval  \\\n",
       "18        ...                 788145932     None   \n",
       "52        ...                1839500317     None   \n",
       "74        ...                1818896580     None   \n",
       "94        ...                 604302163     None   \n",
       "118       ...                 747061712     None   \n",
       "138       ...                1962390220     None   \n",
       "\n",
       "                                            train_file  train_size use_eos  \\\n",
       "18   /mnt/permanent/home/judit/projects/sigmorphon2...        high    True   \n",
       "52   /mnt/permanent/home/judit/projects/sigmorphon2...        high    True   \n",
       "74   /mnt/permanent/home/judit/projects/sigmorphon2...        high    True   \n",
       "94   /mnt/permanent/home/judit/projects/sigmorphon2...        high    True   \n",
       "118  /mnt/permanent/home/judit/projects/sigmorphon2...        high    True   \n",
       "138  /mnt/permanent/home/judit/projects/sigmorphon2...        high    True   \n",
       "\n",
       "     use_step                                     vocab_path_src  \\\n",
       "18      False  /mnt/permanent/home/judit/projects/sigmorphon2...   \n",
       "52      False  /mnt/permanent/home/judit/projects/sigmorphon2...   \n",
       "74      False  /mnt/permanent/home/judit/projects/sigmorphon2...   \n",
       "94      False  /mnt/permanent/home/judit/projects/sigmorphon2...   \n",
       "118     False  /mnt/permanent/home/judit/projects/sigmorphon2...   \n",
       "138     False  /mnt/permanent/home/judit/projects/sigmorphon2...   \n",
       "\n",
       "                                        vocab_path_tgt  word_hidden_size  \\\n",
       "18   /mnt/permanent/home/judit/projects/sigmorphon2...                64   \n",
       "52   /mnt/permanent/home/judit/projects/sigmorphon2...               128   \n",
       "74   /mnt/permanent/home/judit/projects/sigmorphon2...               128   \n",
       "94   /mnt/permanent/home/judit/projects/sigmorphon2...               256   \n",
       "118  /mnt/permanent/home/judit/projects/sigmorphon2...               256   \n",
       "138  /mnt/permanent/home/judit/projects/sigmorphon2...               256   \n",
       "\n",
       "     word_num_layers  \n",
       "18                 2  \n",
       "52                 1  \n",
       "74                 1  \n",
       "94                 1  \n",
       "118                1  \n",
       "138                1  \n",
       "\n",
       "[6 rows x 50 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = task2_track1\n",
    "t[(t.language=='sv') & (t.train_size=='high')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save best configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../config/task2/track1/highest_dev_acc\"\n",
    "\n",
    "\n",
    "keep = ['batch_size', 'char_embedding_size', 'commit_hash', 'context_hidden_size', 'context_num_layers',\n",
    "        'dataset_class', 'decoder_hidden_size', 'decoder_num_layers', \n",
    "        'dev_file', 'dropout', 'early_stopping_window', 'epochs', \n",
    "        'include_same_forms_ratio', 'lemma_hidden_size', 'lemma_num_layers',\n",
    "        'min_epochs', 'model', 'numpy_random_seed', 'optimizer', \n",
    "        'share_context_encoder', 'share_embedding', 'share_vocab', \n",
    "        'tag_embedding_size', 'tag_hidden_size', 'tag_num_layers',\n",
    "        'save_min_epoch',\n",
    "        'torch_random_seed', 'train_file', 'word_hidden_size', 'word_num_layers']\n",
    "\n",
    "for (language, train_size), idx in task2_track1.groupby(['language', 'train_size']).dev_acc.idxmax().iteritems():\n",
    "    out_fn = os.path.join(outdir, \"{}_{}.yaml\".format(language, train_size))\n",
    "    in_config = task2_track1.loc[idx].experiment_dir + \"/config.yaml\"\n",
    "    with open(in_config) as f:\n",
    "        cfg = yaml.load(f)\n",
    "    cfg = {k: v for k, v in cfg.items() if k in keep}\n",
    "    cfg['train_file'] = 'data/conll2018' + cfg['train_file'].split('conll2018')[1]\n",
    "    cfg['dev_file'] = 'data/conll2018' + cfg['dev_file'].split('conll2018')[1]\n",
    "    with open(out_fn, 'w') as f:\n",
    "        yaml.dump(cfg, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission - there is only one\n",
    "\n",
    "choose the one with the highest dev acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dir = \"../submissions/task2/01/task2\"\n",
    "for (language, train_size), idx in task2_track1.groupby(['language', 'train_size']).dev_acc.idxmax().iteritems():\n",
    "    experiment = task2_track1.loc[idx]\n",
    "    target_name = \"{}-1-{}-out\".format(language, train_size)\n",
    "    target_fn = os.path.join(submission_dir, target_name)\n",
    "    shutil.copy2(experiment.test_output_path, target_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dirs = [\"../exps/task2/track2/default/\"]\n",
    "task2_track2 = []\n",
    "\n",
    "for exp_dir in exp_dirs:\n",
    "    for subdir in os.scandir(exp_dir):\n",
    "        config_fn = os.path.join(subdir.path, \"config.yaml\")\n",
    "        with open(config_fn) as f:\n",
    "            config = yaml.load(f)\n",
    "        exp_d = config\n",
    "        exp_d['language'] = config['train_file'].split('/')[-1].split('-')[0]\n",
    "        exp_d['train_size'] = config['train_file'].split('/')[-1].split('-')[2]\n",
    "        dev_acc_fn = os.path.join(subdir.path, \"dev.word_accuracy\")\n",
    "        if not os.path.exists(dev_acc_fn):\n",
    "            print(\"Dev accuracy file does not exist in {}\".format(subdir.path))\n",
    "        else:\n",
    "            with open(dev_acc_fn) as f:\n",
    "                exp_d['dev_acc'] = float(f.read())\n",
    "        test_out_fn = os.path.join(subdir.path, \"test.out\")\n",
    "        if not os.path.exists(test_out_fn):\n",
    "            print(\"Test output file does not exist in {}\".format(subdir.path))\n",
    "        else:\n",
    "            exp_d['test_output_path'] = test_out_fn\n",
    "            \n",
    "        task2_track2.append(exp_d)\n",
    "        \n",
    "task2_track2 = pd.DataFrame(task2_track2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dev_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">de</th>\n",
       "      <th>high</th>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.264264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.531532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">en</th>\n",
       "      <th>high</th>\n",
       "      <td>0.652366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.511628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.563352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">es</th>\n",
       "      <th>high</th>\n",
       "      <td>0.380511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.245150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.284832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">fi</th>\n",
       "      <th>high</th>\n",
       "      <td>0.287613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.057948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.152578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">fr</th>\n",
       "      <th>high</th>\n",
       "      <td>0.477341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.083384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.235045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ru</th>\n",
       "      <th>high</th>\n",
       "      <td>0.635055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.176969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.358171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sv</th>\n",
       "      <th>high</th>\n",
       "      <td>0.595113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.202443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.375218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      dev_acc\n",
       "language train_size          \n",
       "de       high        0.594595\n",
       "         low         0.264264\n",
       "         medium      0.531532\n",
       "en       high        0.652366\n",
       "         low         0.511628\n",
       "         medium      0.563352\n",
       "es       high        0.380511\n",
       "         low         0.245150\n",
       "         medium      0.284832\n",
       "fi       high        0.287613\n",
       "         low         0.057948\n",
       "         medium      0.152578\n",
       "fr       high        0.477341\n",
       "         low         0.083384\n",
       "         medium      0.235045\n",
       "ru       high        0.635055\n",
       "         low         0.176969\n",
       "         medium      0.358171\n",
       "sv       high        0.595113\n",
       "         low         0.202443\n",
       "         medium      0.375218"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2_track2.groupby(['language', 'train_size']).dev_acc.max().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../config/task2/track2/highest_dev_acc\"\n",
    "\n",
    "\n",
    "keep = ['batch_size', 'char_embedding_size', 'commit_hash', 'context_hidden_size', 'context_num_layers',\n",
    "        'dataset_class', 'decoder_hidden_size', 'decoder_num_layers', \n",
    "        'dev_file', 'dropout', 'early_stopping_window', 'epochs', \n",
    "        'include_same_forms_ratio', 'lemma_hidden_size', 'lemma_num_layers',\n",
    "        'min_epochs', 'model', 'numpy_random_seed', 'optimizer', \n",
    "        'share_context_encoder', 'share_embedding', 'share_vocab', \n",
    "        'tag_embedding_size', 'tag_hidden_size', 'tag_num_layers',\n",
    "        'save_min_epoch',\n",
    "        'torch_random_seed', 'train_file', 'word_hidden_size', 'word_num_layers']\n",
    "\n",
    "for (language, train_size), idx in task2_track2.groupby(['language', 'train_size']).dev_acc.idxmax().iteritems():\n",
    "    out_fn = os.path.join(outdir, \"{}_{}.yaml\".format(language, train_size))\n",
    "    in_config = task2_track2.loc[idx].experiment_dir + \"/config.yaml\"\n",
    "    with open(in_config) as f:\n",
    "        cfg = yaml.load(f)\n",
    "    cfg = {k: v for k, v in cfg.items() if k in keep}\n",
    "    cfg['train_file'] = 'data/conll2018' + cfg['train_file'].split('conll2018')[1]\n",
    "    cfg['dev_file'] = 'data/conll2018' + cfg['dev_file'].split('conll2018')[1]\n",
    "    with open(out_fn, 'w') as f:\n",
    "        yaml.dump(cfg, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dir = \"../submissions/task2/01/task2\"\n",
    "for (language, train_size), idx in task2_track2.groupby(['language', 'train_size']).dev_acc.idxmax().iteritems():\n",
    "    experiment = task2_track2.loc[idx]\n",
    "    target_name = \"{}-2-{}-out\".format(language, train_size)\n",
    "    target_fn = os.path.join(submission_dir, target_name)\n",
    "    shutil.copy2(experiment.test_output_path, target_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checks\n",
    "\n",
    "## Task1\n",
    "\n",
    "1. Is every submission file the same length as the input?\n",
    "2. Does every line have 3 fields?\n",
    "3. Do the inputs match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../data/conll2018/task1/all\"\n",
    "submission_dir = \"../submissions/task1\"\n",
    "\n",
    "for submission_no in os.listdir(submission_dir):\n",
    "    for subm_file in os.scandir(os.path.join(submission_dir, submission_no, 'task1')):\n",
    "        language = '-'.join(subm_file.name.split('-')[:-2])\n",
    "        test_fn = os.path.join(test_dir, '{}-covered-test'.format(language))\n",
    "        if not os.path.exists(test_fn):\n",
    "            test_fn = os.path.join(test_dir, \"..\", \"surprise\", '{}-covered-test'.format(language))\n",
    "        with open(test_fn) as input_f, open(subm_file) as output_f:\n",
    "            for inp_line in input_f:\n",
    "                outp_line = next(output_f)\n",
    "                infd = inp_line.strip().split('\\t')\n",
    "                outfd = outp_line.strip().split('\\t')\n",
    "                try:\n",
    "                    assert len(outfd) == 3\n",
    "                    assert infd[0] == outfd[0]\n",
    "                    assert infd[-1] == outfd[-1]\n",
    "                except AssertionError:\n",
    "                    print(submission_no, subm_file.path, infd, outfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"../data/conll2018/task2/testsets/\"\n",
    "submission_dir = \"../submissions/task2\"\n",
    "\n",
    "for submission_no in os.listdir(submission_dir):\n",
    "    for subm_file in os.scandir(os.path.join(submission_dir, submission_no, 'task2')):\n",
    "        language = subm_file.name.split('-')[0]\n",
    "        track = subm_file.name.split('-')[1]\n",
    "        test_fn = os.path.join(test_dir, '{}-track{}-covered'.format(language, track))\n",
    "        with open(test_fn) as input_f, open(subm_file) as output_f:\n",
    "            for inp_line in input_f:\n",
    "                outp_line = next(output_f)\n",
    "                if not inp_line.strip():\n",
    "                    assert not outp_line.strip()\n",
    "                    continue\n",
    "                infd = inp_line.strip().split('\\t')\n",
    "                outfd = outp_line.strip().split('\\t')\n",
    "                if track == '1':\n",
    "                    try:\n",
    "                        assert len(outfd) == 3\n",
    "                        assert infd[2] == outfd[2]\n",
    "                    except AssertionError:\n",
    "                        print(inp_line)\n",
    "                        print(outp_line)\n",
    "                        print(submission_no, subm_file.path, infd, outfd)\n",
    "                elif track == '2':\n",
    "                    pass\n",
    "                else:\n",
    "                    raise ValueError(\"unknown track: {}\".format(track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission archives\n",
    "\n",
    "## Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "02\n",
      "03\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "old_pwd=$(pwd)\n",
    "\n",
    "for sub in $( ls ../submissions/task1); do\n",
    "    tar_name=\"BME-HAS-$sub-1.tgz\"\n",
    "    echo $sub\n",
    "    cd ../submissions/task1/$sub\n",
    "    mkdir -p arabic_slovene_fixed\n",
    "    mkdir -p arabic_slovene_fixed/task1\n",
    "    cp task1/arabic* arabic_slovene_fixed/task1\n",
    "    cp task1/slovene* arabic_slovene_fixed/task1\n",
    "    cd arabic_slovene_fixed\n",
    "    tar czf $tar_name task1\n",
    "    mv $tar_name ../../../tgz/arabic_slovene_fixed/\n",
    "    cd $old_pwd\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for sub in $( ls ../submissions/task1); do\n",
    "    tar_name=\"BME-HAS-$sub-1.tgz\"\n",
    "    cd ../submissions/task1/$sub\n",
    "    tar czf $tar_name task1\n",
    "    mv $tar_name ../../tgz\n",
    "    cd -\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for sub in $( ls ../submissions/task2); do\n",
    "    tar_name=\"BME-HAS-$sub-2.tgz\"\n",
    "    cd ../submissions/task2/$sub\n",
    "    tar czf $tar_name task2\n",
    "    mv $tar_name ../../tgz\n",
    "    cd -\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
