{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.pyplot.rcParams['figure.figsize'] = (15, 6)\n",
    "matplotlib.pyplot.rcParams['font.family'] = 'sans-serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparsity(model_fn, threshold=10e-3):\n",
    "    is_zero = 0\n",
    "    non_zero = 0\n",
    "    for name, tensor in torch.load(model_fn).items():\n",
    "        m = tensor.cpu().numpy()\n",
    "        close = len(np.where(np.abs(m) <= threshold)[0])\n",
    "        is_zero += close\n",
    "        non_zero += (m.size - close)\n",
    "    return is_zero, non_zero, is_zero / (is_zero + non_zero)\n",
    "    \n",
    "    \n",
    "def get_min_loss(row):\n",
    "    min_idx, min_dev_loss = min(enumerate(row['dev_loss']), key=lambda x: x[1])\n",
    "    min_train_loss = row['train_loss'][min_idx]\n",
    "    row['min_dev_loss'] = min_dev_loss\n",
    "    row['min_train_loss'] = min_train_loss\n",
    "    return row\n",
    "    \n",
    "    \n",
    "def extract_language_name(field):\n",
    "    fn = field.split('/')[-1]\n",
    "    if 'dev' in fn:\n",
    "        return '-'.join(fn.split('-')[:-1])\n",
    "    return '-'.join(fn.split('-')[:-2])\n",
    "    \n",
    "\n",
    "def load_res_dir(basedir, include_sparsity=False):\n",
    "    experiments = []\n",
    "    for subdir in os.scandir(basedir):\n",
    "        exp_d = {}\n",
    "        with open(os.path.join(subdir.path, \"config.yaml\")) as f:\n",
    "            exp_d.update(yaml.load(f))\n",
    "        res_fn = os.path.join(subdir.path, \"result.yaml\")\n",
    "        if os.path.exists(res_fn):\n",
    "            with open(os.path.join(subdir.path, \"result.yaml\")) as f:\n",
    "                exp_d.update(yaml.load(f))\n",
    "        else:\n",
    "            continue\n",
    "        dev_acc_path = os.path.join(subdir.path, \"dev.word_accuracy\")\n",
    "        if os.path.exists(dev_acc_path):\n",
    "            with open(dev_acc_path) as f:\n",
    "                exp_d['dev_acc'] = float(f.read())\n",
    "        else:\n",
    "            print(\"Dev accuracy file does not exist in dir: {}\".format(subdir.path))\n",
    "        if include_sparsity:\n",
    "            exp_d['sparsity'] = compute_sparsity(os.path.join(subdir.path, \"model\"), 10e-4)\n",
    "        experiments.append(exp_d)\n",
    "    experiments = pd.DataFrame(experiments)\n",
    "    if include_sparsity:\n",
    "        experiments['sparsity_ratio'] = experiments['sparsity'].apply(lambda x: x[2])\n",
    "    experiments['language'] = experiments.dev_file.apply(extract_language_name)\n",
    "    experiments = experiments.apply(get_min_loss, axis=1)\n",
    "    experiments = experiments[experiments['dev_acc'].notnull()]\n",
    "    experiments = experiments[experiments['dev_loss'].notnull()]\n",
    "    experiments['train_size'] = experiments['train_file'].apply(lambda fn: fn.split('-')[-1])\n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.2 s, sys: 196 ms, total: 39.4 s\n",
      "Wall time: 40.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "luong = pd.concat([\n",
    "    load_res_dir(\"../exps/task1/luong/\"),\n",
    "    load_res_dir(\"../exps/task1/reverse_luong/\"),\n",
    "    load_res_dir(\"../exps/task1/luong_new/\"),\n",
    "    load_res_dir(\"../exps/task1/reverse_luong_new/\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2157, 44)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luong.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataset_name(row):\n",
    "    row['dataset'] = \"{}:{}\".format(row['language'], row['train_size'])\n",
    "    return row\n",
    "\n",
    "luong = luong.apply(extract_dataset_name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reverse  new  \n",
       "False    False    728\n",
       "         True     585\n",
       "True     False    582\n",
       "         True     262\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luong[\"reverse\"] = luong.train_file.str.contains(\"reverse\")\n",
    "luong[\"new\"] = luong.experiment_dir.str.contains(\"_new\")\n",
    "\n",
    "luong.groupby(['reverse', 'new']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is on-the-fly padding better than global padding\n",
    "\n",
    "On-the-fly padding: pad every sample to the longest sample in the current batch\n",
    "\n",
    "global padding: pad to the longest sample in the whole dataset\n",
    "\n",
    "\n",
    "On-the-fly padding is much better if the target is not reversed. It is slightly better if the target is reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>reverse</th>\n",
       "      <th colspan=\"2\" halign=\"left\">False</th>\n",
       "      <th colspan=\"2\" halign=\"left\">True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.714058</td>\n",
       "      <td>0.763748</td>\n",
       "      <td>0.744194</td>\n",
       "      <td>0.748538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.355039</td>\n",
       "      <td>0.348587</td>\n",
       "      <td>0.343788</td>\n",
       "      <td>0.354439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>0.773500</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.970500</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "reverse       False                   True            \n",
       "new           False       True        False      True \n",
       "count    103.000000  103.000000  103.000000  93.000000\n",
       "mean       0.714058    0.763748    0.744194   0.748538\n",
       "std        0.355039    0.348587    0.343788   0.354439\n",
       "min        0.000000    0.000000    0.000000   0.000000\n",
       "25%        0.587000    0.806500    0.773500   0.780000\n",
       "50%        0.880000    0.906000    0.870000   0.892000\n",
       "75%        0.964000    0.970500    0.964000   0.972000\n",
       "max        1.000000    1.000000    1.000000   1.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luong.groupby(['language', 'reverse', 'new']).max()['dev_acc'].unstack(['reverse', 'new']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "haida                 1.000\n",
       "tatar                 1.000\n",
       "pashto                1.000\n",
       "occitan               1.000\n",
       "uzbek                 1.000\n",
       "crimean-tatar         1.000\n",
       "neapolitan            1.000\n",
       "swahili               1.000\n",
       "kabardian             1.000\n",
       "bashkir               0.999\n",
       "venetian              0.998\n",
       "khaling               0.997\n",
       "urdu                  0.996\n",
       "adyghe                0.995\n",
       "middle-french         0.994\n",
       "persian               0.994\n",
       "friulian              0.990\n",
       "albanian              0.990\n",
       "basque                0.984\n",
       "quechua               0.982\n",
       "galician              0.982\n",
       "yiddish               0.980\n",
       "maltese               0.980\n",
       "estonian              0.980\n",
       "zulu                  0.980\n",
       "hebrew                0.971\n",
       "georgian              0.970\n",
       "classical-syriac      0.970\n",
       "lower-sorbian         0.969\n",
       "italian               0.967\n",
       "                      ...  \n",
       "romanian              0.831\n",
       "greek                 0.829\n",
       "old-english           0.823\n",
       "faroese               0.812\n",
       "lithuanian            0.801\n",
       "breton                0.800\n",
       "swedish               0.797\n",
       "votic                 0.790\n",
       "navajo                0.785\n",
       "norwegian-nynorsk     0.740\n",
       "arabic                0.674\n",
       "latin                 0.653\n",
       "livonian              0.560\n",
       "telugu                0.060\n",
       "kashubian             0.000\n",
       "murrinhpatha          0.000\n",
       "old-irish             0.000\n",
       "scottish-gaelic       0.000\n",
       "norman                0.000\n",
       "middle-low-german     0.000\n",
       "tibetan               0.000\n",
       "karelian              0.000\n",
       "middle-high-german    0.000\n",
       "mapudungun            0.000\n",
       "greenlandic           0.000\n",
       "ingrian               0.000\n",
       "khakas                0.000\n",
       "kazakh                0.000\n",
       "turkmen               0.000\n",
       "cornish               0.000\n",
       "Name: dev_acc, Length: 103, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = luong[(luong.reverse==False) & (luong.new==True)]\n",
    "df.groupby('language').dev_acc.max().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
