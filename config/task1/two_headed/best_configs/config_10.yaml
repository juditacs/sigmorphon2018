batch_size: 128
dataset_class: ReinflectionDataset
dropout: 0.4
early_stopping_strategy: dev_loss_increase
early_stopping_window: 5
epochs: 200
experiment_dir: exps/task1/two_headed_best
inflected_embedding_size: 20
inflected_hidden_size: 512
inflected_num_layers: 2
language: latin
lemma_embedding_size: 20
lemma_hidden_size: 512
lemma_num_layers: 4
model: ReinflectionSeq2seq
optimizer: Adam
save_min_epoch: 0
share_embedding: false
share_vocab: false
tag_embedding_size: 10
tag_hidden_size: 128
tag_num_layers: 2
